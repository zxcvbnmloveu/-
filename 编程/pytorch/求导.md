# `求导`

构建深度学习模型的基本流程就是：搭建计算图，求得预测值，进而得到损失，然后计算损失对模型参数的导数，再利用梯度下降法等方法来更新参数。

搭建计算图的过程，称为“正向传播”，这个是需要我们自己动手的，因为我们需要设计我们模型的结构。由损失函数求导的过程，称为“反向传播”。

如果要对tensor求导，需设置```.requires_grad_()  ```

#### 例子
```python3
import torch

a = torch.tensor([1.,1.]).requires_grad_()
b = torch.tensor([2.,2.]).requires_grad_()
c = torch.tensor([3.,3.]).requires_grad_()

ans = torch.sum(a*b+c)
# 求导需要是一个数
print(ans)
print(a.grad,b.grad,c.grad)
ans.backward()
print(a.grad,b.grad,c.grad)

```

```
tensor(10., grad_fn=<SumBackward0>)
None None None
tensor([2., 2.]) tensor([1., 1.]) tensor([1., 1.])
```

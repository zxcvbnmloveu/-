# `特征选择`

### 目的 

寻找最优特征子集，剔除不相关，冗余特征，提高模型准确度，减少运行时间。防止过拟合（过拟合是因为模型参数太贴合训练集特征，把共有特征挑选出来就可以减轻过拟合）

一般分为filter,wrapper,embedded.

### **filter** 

* 对各个特征进行评分，比如皮尔逊相关系数（线性相关，一般用于回归），距离相关系数（非线性）,卡方检验（比如），看特征跟类别标签是否相关，达到某个阈值，或排序进行选择。或方差过滤（如果某变量所有样本都相同，比如都是1，那这个特征没用。）

### 卡方检验例子（本质就是如果某变量对结果无影响，那么在某个结果类别上比例应该还是一致，条件概率）
已知所有人300+1200=1600中：
喜欢下象棋的人/不喜欢下象棋的人=300/1200=1/4
我们假设下象棋与喜欢科幻电影二者之间没有影响，那么：
喜欢科幻电影的450人中，有450*（1/4）=90的人喜欢象棋，360人不喜欢象棋
不喜欢科幻电影的1050人中，有1050*（1/4）=210人喜欢象棋，840人不喜欢象棋
以上计算出的（表格中红色部分）就是我们假设的理论值，黑色的就是实际值
利用卡方计算公式，计算得到卡方值为507.93
此时的自由度为1，置信度为0.01时，对应的临界值为10.83
因为507.93＞10.83，所以假设（无影响）不成立，也就是二者之间有影响。

### **wrapper** 根据目标函数（一般使用acc），前向搜索（从一个特征开始，逐步增加），后向搜索（全集逐渐排除）。

### **embedded** 加正则项，比如加L1产生稀疏解，相当于做了特征选择
